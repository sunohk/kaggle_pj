{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":52784,"databundleVersionId":5687476,"sourceType":"competition"}],"dockerImageVersionId":30513,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.03885,"end_time":"2023-07-04T13:21:44.696238","exception":false,"start_time":"2023-07-04T13:21:44.657388","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:27:39.326440Z","iopub.execute_input":"2023-08-05T09:27:39.327548Z","iopub.status.idle":"2023-08-05T09:27:39.339764Z","shell.execute_reply.started":"2023-08-05T09:27:39.327510Z","shell.execute_reply":"2023-08-05T09:27:39.338973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"color:#D81F26;\n           display:fill;\n           border-style: solid;\n           border-color:#C1C1C1;\n           font-size:14px;\n           font-family:Calibri;\n           background-color:#373737;\">\n<h2 style=\"text-align: center;\n           padding: 10px;\n           color:#FFFFFF;\">\n======= ICR - Identifying Age-Related Conditions  =======\n</h2>\n</div>","metadata":{"papermill":{"duration":0.018391,"end_time":"2023-07-04T13:21:44.733331","exception":false,"start_time":"2023-07-04T13:21:44.714940","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 1. About this Notebook\nThe \"ICR: Identify Age-Related Conditions\" Kaggle competition challenges participants to develop predictive models that can accurately identify age-related conditions in individuals. With access to a provided dataset containing demographic and medical information, participants create machine learning models to predict the presence or likelihood of age-related conditions. \n\n## Summary\n1. The distribution of the target feature is analyzed to assess the imbalance between the values 1 and 0, which helps determine if oversampling is necessary.\n2. An analysis of missing values is conducted to check for presence of missing values, which will impact machine learning at later process.\n3. Histograms and box plots are employed to visualize the skewness and identify outliers, aiding in the selection of appropriate methods for data standardization.\n3. For data processing, the Robust Scaler is chosen to standardize the numerical features, taking into account outlier handling. Additionally, the CatBoost Encoder is utilized for encoding categorical features, and the kNN Imputer is employed for handling missing values.\n4. In order to address the class imbalance, the SMOTE (Synthetic Minority Over-sampling Technique) is employed for oversampling the minority class, generating synthetic samples to balance the dataset.\n5. SelectKBest feature selection method is used to select those features with low p-value with the taget label.   \n5. Lastly, various base classifiers with hyperparameter tuning are applied.\n\n","metadata":{"papermill":{"duration":0.018018,"end_time":"2023-07-04T13:21:44.770619","exception":false,"start_time":"2023-07-04T13:21:44.752601","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Version\n* Version 2: Baseline with XGBoost\n* Version 3: Add KBestFeature selection method from sklearn packages for feature selection\n* Version 4: Add LGBM classifier to form voting decision with XGBoost together\n* Version 5: Skip the Robust Scaler to test the performance and add build-in feature importance from Tree-based models\n* Version 6: Add Logistic Regression and SVC to form ensemble classification\n* Version 7: Change the hyperparameter space of XGBoost and LGBM","metadata":{"papermill":{"duration":0.018103,"end_time":"2023-07-04T13:21:44.807045","exception":false,"start_time":"2023-07-04T13:21:44.788942","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 1.1. Library Setup","metadata":{"papermill":{"duration":0.017958,"end_time":"2023-07-04T13:21:44.843211","exception":false,"start_time":"2023-07-04T13:21:44.825253","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\n%matplotlib inline\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom catboost import CatBoostClassifier\nfrom sklearn.svm import SVC\nimport random\nfrom scipy.stats import uniform, randint\n\n# Suppress any warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, GridSearchCV\nfrom sklearn import metrics\n\n# kNN Imputation\nfrom sklearn.impute import KNNImputer\n\n# Feature Selection\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\n# Data Encoder and Scaler\nimport category_encoders as encoders\nfrom sklearn.preprocessing import LabelEncoder, RobustScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import Normalizer\n\n# SMOTE (Synthetic Minority Over-sampling Technique)\nfrom imblearn.over_sampling import SMOTE\n","metadata":{"_kg_hide-output":true,"papermill":{"duration":4.973878,"end_time":"2023-07-04T13:21:49.835568","exception":false,"start_time":"2023-07-04T13:21:44.861690","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:27:39.345446Z","iopub.execute_input":"2023-08-05T09:27:39.345761Z","iopub.status.idle":"2023-08-05T09:27:40.780747Z","shell.execute_reply.started":"2023-08-05T09:27:39.345733Z","shell.execute_reply":"2023-08-05T09:27:40.779889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2. Load the Data","metadata":{"papermill":{"duration":0.018779,"end_time":"2023-07-04T13:21:49.873310","exception":false,"start_time":"2023-07-04T13:21:49.854531","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Read the train, test and greeks data\n\ndf_train = pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/test.csv\")\ndf_greeks = pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/greeks.csv\")\n\nprint('No. of records for train : {}'.format(df_train.shape))\nprint('No. of records for test : {}'.format(df_test.shape))\nprint('No. of records for greeks : {}'.format(df_greeks.shape))","metadata":{"papermill":{"duration":0.064853,"end_time":"2023-07-04T13:21:49.956601","exception":false,"start_time":"2023-07-04T13:21:49.891748","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:27:40.782009Z","iopub.execute_input":"2023-08-05T09:27:40.782327Z","iopub.status.idle":"2023-08-05T09:27:40.812400Z","shell.execute_reply.started":"2023-08-05T09:27:40.782292Z","shell.execute_reply":"2023-08-05T09:27:40.811200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. EDA","metadata":{"papermill":{"duration":0.017985,"end_time":"2023-07-04T13:21:49.992964","exception":false,"start_time":"2023-07-04T13:21:49.974979","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 2.1. Distribution of Target Label\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nTo check if the distribution of target feature (i.e. Class) is balanced.  If it is not the case, we will do oversampling of SMOTE (Synthetic Minority Over-sampling Technique) algorithm in the modelling process.  \n</div>","metadata":{"papermill":{"duration":0.017716,"end_time":"2023-07-04T13:21:50.028647","exception":false,"start_time":"2023-07-04T13:21:50.010931","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# check whether the data set is balanced\n\nplt.figure(figsize=(5,5))\n\ndef auto_fmt (pct_value):\n    return '{:.0f}\\n({:.2f}%)'.format(df_train['Class'].value_counts().sum()*pct_value/100,pct_value) \n\ndf_transported_count = df_train['Class'].value_counts().rename_axis('Class').reset_index(name='Counts')\n\nfig = plt.gcf()\nplt.pie(x=df_transported_count['Counts'], labels=df_transported_count['Class'], autopct=auto_fmt, textprops={'fontsize': 12})\nplt.title('Distribution of Target Label (i.e. Class)',  fontsize = 14)","metadata":{"papermill":{"duration":0.21355,"end_time":"2023-07-04T13:21:50.260213","exception":false,"start_time":"2023-07-04T13:21:50.046663","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:27:40.816218Z","iopub.execute_input":"2023-08-05T09:27:40.816628Z","iopub.status.idle":"2023-08-05T09:27:41.145289Z","shell.execute_reply.started":"2023-08-05T09:27:40.816597Z","shell.execute_reply":"2023-08-05T09:27:41.143697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservation: the distribution of target feature between 1 and 0 cases is uneven. It may be necessary to do oversampling, e.g. SMOTE (Synthetic Minority Over-sampling Technique).\n</div>\n","metadata":{"papermill":{"duration":0.028793,"end_time":"2023-07-04T13:21:50.329876","exception":false,"start_time":"2023-07-04T13:21:50.301083","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 2.2. Missing Value Analysis\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\n\nMissing values in machine learning can have a significant impact on the performance and accuracy of models, and most machine learning algorithms cannot handle missing value.  To address missing values, imputation techniques are often used to estimate or fill in the missing data.\n</div>","metadata":{"papermill":{"duration":0.018512,"end_time":"2023-07-04T13:21:50.367280","exception":false,"start_time":"2023-07-04T13:21:50.348768","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Only include numerical features\ndf_train_numerical = df_train.drop(['Id', 'EJ', 'Class'], axis=1)","metadata":{"papermill":{"duration":0.029134,"end_time":"2023-07-04T13:21:50.415147","exception":false,"start_time":"2023-07-04T13:21:50.386013","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:27:41.147440Z","iopub.execute_input":"2023-08-05T09:27:41.148026Z","iopub.status.idle":"2023-08-05T09:27:41.161513Z","shell.execute_reply.started":"2023-08-05T09:27:41.147978Z","shell.execute_reply":"2023-08-05T09:27:41.159690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(10, 6))\n\n# No. of missing values by features\ndf_train_missing = df_train_numerical.isna().sum()\n\n# Resetting the index\ndf_train_missing = df_train_missing.reset_index()\n\n# Renaming the columns\ndf_train_missing.columns = ['feature', 'missing_count']\n\n# Filtering features with missing values\ndf_train_missing = df_train_missing.loc[df_train_missing['missing_count'] > 0]\n\n# Create a bar chart\ndf_train_missing.plot.bar(x='feature', y='missing_count')\n\n# Set the chart title and axis labels\nplt.title('Missing Values Count', fontsize=16)\nplt.xlabel('Columns', fontsize=14)\nplt.ylabel('Count', fontsize=14)\n\nplt.tick_params(axis='x', which='major', labelsize=14)\nplt.tick_params(axis='y', which='major', labelsize=14)\n\n# Display the chart\nplt.show()\n\n","metadata":{"papermill":{"duration":0.341125,"end_time":"2023-07-04T13:21:50.775371","exception":false,"start_time":"2023-07-04T13:21:50.434246","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:27:41.163444Z","iopub.execute_input":"2023-08-05T09:27:41.164765Z","iopub.status.idle":"2023-08-05T09:27:41.481575Z","shell.execute_reply.started":"2023-08-05T09:27:41.164700Z","shell.execute_reply":"2023-08-05T09:27:41.480539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservations: The features BQ and EL exhibit a high number of missing values, while some other features also have a few missing values. In order to tackle this issue, we will perform imputation to handle the missing values.\n</div>\n","metadata":{"papermill":{"duration":0.019111,"end_time":"2023-07-04T13:21:50.813784","exception":false,"start_time":"2023-07-04T13:21:50.794673","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 2.3. Descritpive Analysis\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\n\nDescriptive analysis refers to the process of summarizing and interpreting data to gain insights and understand its main characteristics. It involves the use of various statistical measures and visualization techniques to describe and present data in a meaningful way.\n</div>","metadata":{"papermill":{"duration":0.018867,"end_time":"2023-07-04T13:21:50.851864","exception":false,"start_time":"2023-07-04T13:21:50.832997","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Exclude the target label Class and categorical feature EJ in the Describe analysis\n# Since there are too many colums for Describe analysis, we need to transpose the results. \n\ndf_train_numerical.describe(include='all').transpose()","metadata":{"papermill":{"duration":0.180979,"end_time":"2023-07-04T13:21:51.052016","exception":false,"start_time":"2023-07-04T13:21:50.871037","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:27:41.482921Z","iopub.execute_input":"2023-08-05T09:27:41.483228Z","iopub.status.idle":"2023-08-05T09:27:41.633182Z","shell.execute_reply.started":"2023-08-05T09:27:41.483203Z","shell.execute_reply":"2023-08-05T09:27:41.632012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.4. Histogram Analysis for Skewness\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nIt examines the shape of the distribution displayed in a histogram to determine the skewness of the data.\n</div>","metadata":{"papermill":{"duration":0.020086,"end_time":"2023-07-04T13:21:51.094701","exception":false,"start_time":"2023-07-04T13:21:51.074615","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Histgram for numercial features\nfig, ax = plt.subplots(11, 5, figsize=(16,30))\n\nfor i in range(0, (len(ax.flatten()))):\n#     print('{}, {}'.format(int(i/5),i % 5))\n    sns.histplot(data=df_train_numerical, x =df_train_numerical.iloc[:,i], bins=20, ax=ax[int(i/5),i % 5])\n#     ax[int(i/5), i % 5].set_title(df_train_numerical.columns[i])\n\n# Adjust the vertical spacing between subplots    \nplt.subplots_adjust(hspace=0.5)  \n\nplt.show()","metadata":{"papermill":{"duration":9.083979,"end_time":"2023-07-04T13:22:00.199148","exception":false,"start_time":"2023-07-04T13:21:51.115169","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:27:41.634466Z","iopub.execute_input":"2023-08-05T09:27:41.635389Z","iopub.status.idle":"2023-08-05T09:27:51.038163Z","shell.execute_reply.started":"2023-08-05T09:27:41.635357Z","shell.execute_reply":"2023-08-05T09:27:51.036974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class 컬럼값이 0인 데이터만 추려내기\ndf_train_class0 = df_train[df_train['Class'] == 0]\n\n# Histgram for class0 columns\nfig, ax = plt.subplots(11, 5, figsize=(16, 30))\n\nfor i in range(1, len(ax.flatten()) + 1):\n    plt.subplot(11, 5, i)\n    column_name = df_train_class0.columns[i - 1]\n    sns.histplot(data=df_train_class0, x=column_name, color='blue', alpha=0.6, stat='count')\n    sns.histplot(data=df_train[df_train['Class'] == 1], x=column_name, color='red', alpha=0.6, stat='count')\n    plt.title(column_name)\n\n# Adjust the vertical spacing between subplots\nplt.subplots_adjust(hspace=0.5)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-05T09:27:51.039412Z","iopub.execute_input":"2023-08-05T09:27:51.039808Z","iopub.status.idle":"2023-08-05T09:28:33.160286Z","shell.execute_reply.started":"2023-08-05T09:27:51.039767Z","shell.execute_reply":"2023-08-05T09:28:33.159149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 특정 컬럼별 그래프 확인","metadata":{}},{"cell_type":"code","source":"# 특정 컬럼 이름\ntarget_column_name = \"AR\"  # 원하는 컬럼의 이름을 입력하세요.\n\n# class 컬럼값이 0인 데이터만 추려내기\ndf_train_class0 = df_train[df_train['Class'] == 0]\n\n# Histgram for class0 columns\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))  # 하나의 subplot만 생성\n\nsns.histplot(data=df_train_class0, x=target_column_name, color='blue', alpha=0.6, stat='count')\nsns.histplot(data=df_train[df_train['Class'] == 1], x=target_column_name, color='red', alpha=0.6, stat='count')\nplt.title(target_column_name)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-05T09:28:33.161704Z","iopub.execute_input":"2023-08-05T09:28:33.162076Z","iopub.status.idle":"2023-08-05T09:28:33.475356Z","shell.execute_reply.started":"2023-08-05T09:28:33.162043Z","shell.execute_reply":"2023-08-05T09:28:33.474214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"AB\"].describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T09:28:33.476444Z","iopub.execute_input":"2023-08-05T09:28:33.477386Z","iopub.status.idle":"2023-08-05T09:28:33.487233Z","shell.execute_reply.started":"2023-08-05T09:28:33.477350Z","shell.execute_reply":"2023-08-05T09:28:33.486465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class 컬럼 값이 0인 경우에 해당하는 AB 컬럼의 기술 통계량 출력\nclass0_describe = df_train[df_train[\"Class\"] == 0][\"AB\"].describe()\nclass0_describe","metadata":{"execution":{"iopub.status.busy":"2023-08-05T09:28:33.488292Z","iopub.execute_input":"2023-08-05T09:28:33.489205Z","iopub.status.idle":"2023-08-05T09:28:33.501756Z","shell.execute_reply.started":"2023-08-05T09:28:33.489174Z","shell.execute_reply":"2023-08-05T09:28:33.500847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class 컬럼 값이 0인 경우에 해당하는 AB 컬럼의 기술 통계량 출력\nclass1_describe = df_train[df_train[\"Class\"] == 1][\"AB\"].describe()\nclass1_describe","metadata":{"execution":{"iopub.status.busy":"2023-08-05T09:28:33.508882Z","iopub.execute_input":"2023-08-05T09:28:33.509913Z","iopub.status.idle":"2023-08-05T09:28:33.525102Z","shell.execute_reply.started":"2023-08-05T09:28:33.509863Z","shell.execute_reply":"2023-08-05T09:28:33.524044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class 컬럼 값이 0인 경우에 해당하는 AB 컬럼의 기술 통계량 출력\nclass0_col_val_cnt = df_train[(df_train[\"Class\"] == 0) & (df_train[\"AB\"] == 0.26)]\nclass0_col_val_cnt","metadata":{"execution":{"iopub.status.busy":"2023-08-05T09:28:33.527782Z","iopub.execute_input":"2023-08-05T09:28:33.528127Z","iopub.status.idle":"2023-08-05T09:28:33.556636Z","shell.execute_reply.started":"2023-08-05T09:28:33.528098Z","shell.execute_reply":"2023-08-05T09:28:33.555618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.5. Boxplot Analysis for Outliers\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nIt identifies and analyzes outliers in a dataset. A boxplot is a graphical representation that displays the distribution of data and provides insights into the presence of outliers. Here's how you can perform boxplot analysis for outliers\n</div>","metadata":{"papermill":{"duration":0.022361,"end_time":"2023-07-04T13:22:00.244672","exception":false,"start_time":"2023-07-04T13:22:00.222311","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Histgram for numercial features\nfig, ax = plt.subplots(11, 5, figsize=(16,30))\n\nfor i in range(0, (len(ax.flatten()))):\n    sns.boxplot(x=\"Class\",y=df_train_numerical.columns[i],data=df_train, ax=ax[int(i/5),i % 5])\n\n# Adjust the vertical spacing between subplots    \nplt.subplots_adjust(wspace=0.3)  \n\nplt.show()","metadata":{"papermill":{"duration":6.224596,"end_time":"2023-07-04T13:22:06.491511","exception":false,"start_time":"2023-07-04T13:22:00.266915","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:33.558184Z","iopub.execute_input":"2023-08-05T09:28:33.559502Z","iopub.status.idle":"2023-08-05T09:28:39.539895Z","shell.execute_reply.started":"2023-08-05T09:28:33.559456Z","shell.execute_reply":"2023-08-05T09:28:39.538759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 특정 컬럼 이상치 그래프","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 특정 컬럼 이름\ntarget_column_name = \"AF\"  # 원하는 컬럼의 이름을 입력하세요.\n\n# Boxplot for class 0 and 1 columns\nfig, ax = plt.subplots(1, 1, figsize=(6, 4))  # 하나의 subplot만 생성\n\nsns.boxplot(x=\"Class\", y=target_column_name, data=df_train)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-05T09:28:39.541528Z","iopub.execute_input":"2023-08-05T09:28:39.542292Z","iopub.status.idle":"2023-08-05T09:28:39.697152Z","shell.execute_reply.started":"2023-08-05T09:28:39.542253Z","shell.execute_reply":"2023-08-05T09:28:39.696011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservations: based on the descriptive and histogram analysis, it is evident that the numerical features display different variances and distributions. To ensure consistency and comparability, it is crucial to standardize the features by rescaling them before proceeding with the modeling process.\n<br><br>\nFurthermore, the box plot analysis reveals the presence of outliers in several numerical features. To address the skewness and outliers effectively, we propose utilizing the Robust Scaler for standardizing the numerical features. \n<br><br>    \nThe Robust Scaler is well-suited for this task as it can automatically handle outliers during the scaling process, providing robustness to extreme values. By employing the Robust Scaler, we can mitigate the impact of outliers and achieve a more reliable and accurate modeling outcome.\n</div>\n","metadata":{"papermill":{"duration":0.025877,"end_time":"2023-07-04T13:22:06.543253","exception":false,"start_time":"2023-07-04T13:22:06.517376","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 2.6. Count Plot for Distribution of Categorical Features\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nThis plot is a type of visualization that displays the distribution of categorical features in a dataset. It represents the frequency or count of each category or class within a categorical variable.\n</div>","metadata":{"papermill":{"duration":0.025365,"end_time":"2023-07-04T13:22:06.594155","exception":false,"start_time":"2023-07-04T13:22:06.568790","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Set the size of the chart\nplt.figure(figsize=(5, 4))\nplt.legend(fontsize=13)\n\n# Create the count plot\nsns.countplot(data=df_train, x='EJ', hue='Class')\n\n# Set the labels and title\nplt.xlabel('EJ', fontsize=14)\nplt.ylabel('Count', fontsize=14)\nplt.title('Count Plot of EJ with Class', fontsize=16)\n\n# Adjust the tick label size\nplt.tick_params(axis='x', which='major', labelsize=14)\nplt.tick_params(axis='y', which='major', labelsize=14)\n\n# Add a legend\nplt.legend(title='Class')\n\nplt.show()","metadata":{"papermill":{"duration":0.286694,"end_time":"2023-07-04T13:22:06.906399","exception":false,"start_time":"2023-07-04T13:22:06.619705","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:39.699187Z","iopub.execute_input":"2023-08-05T09:28:39.699994Z","iopub.status.idle":"2023-08-05T09:28:39.922143Z","shell.execute_reply.started":"2023-08-05T09:28:39.699936Z","shell.execute_reply":"2023-08-05T09:28:39.921042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Data Pre-processing for Model Data","metadata":{"execution":{"iopub.execute_input":"2023-06-17T17:41:11.736765Z","iopub.status.busy":"2023-06-17T17:41:11.736473Z","iopub.status.idle":"2023-06-17T17:41:11.741672Z","shell.execute_reply":"2023-06-17T17:41:11.740624Z","shell.execute_reply.started":"2023-06-17T17:41:11.736744Z"},"papermill":{"duration":0.02555,"end_time":"2023-07-04T13:22:06.958312","exception":false,"start_time":"2023-07-04T13:22:06.932762","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 3.1. Missing Value Imputation - kNN Imputer\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nMissing value imputation using kNN (k-nearest neighbors) imputer is a technique that fills in missing values in a dataset by estimating them based on the values of their k nearest neighbors. It leverages the similarities between samples to impute missing values, making it a useful method for handling incomplete data.\n</div>\n","metadata":{"papermill":{"duration":0.025675,"end_time":"2023-07-04T13:22:07.009982","exception":false,"start_time":"2023-07-04T13:22:06.984307","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Initialize the KNNImputer with the desired number of neighbors\nimputer = KNNImputer(n_neighbors=10) #replace 3 // train set(431)의 제곱근 20\n\n# Perform KNN imputation\ndf_train_imputed = pd.DataFrame(imputer.fit_transform(df_train[df_train_numerical.columns]), columns=df_train_numerical.columns)\ndf_test_imputed =pd.DataFrame(imputer.transform(df_test[df_train_numerical.columns]), columns=df_train_numerical.columns)\n","metadata":{"papermill":{"duration":0.065174,"end_time":"2023-07-04T13:22:07.100769","exception":false,"start_time":"2023-07-04T13:22:07.035595","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:39.923793Z","iopub.execute_input":"2023-08-05T09:28:39.924481Z","iopub.status.idle":"2023-08-05T09:28:39.961365Z","shell.execute_reply.started":"2023-08-05T09:28:39.924439Z","shell.execute_reply":"2023-08-05T09:28:39.960142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if there are still missing values in the train and test data sets\ndf_train_null = df_train_imputed[df_train_imputed.isnull().any(axis=1)]\ndf_test_null = df_test_imputed[df_test_imputed.isnull().any(axis=1)]\n\n# Display the rows with null values\nprint('No. of records with missing value in Train data set after Imputation : {}'.format(df_train_null.shape[0]))\nprint('No. of records with missing value in Test data set after Imputation : {}'.format(df_test_null.shape[0]))\n\n# Check the shape of the train and test data set \nprint('=' * 50)\nprint('Shape of the Train data set : {}'.format(df_train_imputed.shape))\nprint('Shape of the Test data set : {}'.format(df_test_imputed.shape))","metadata":{"papermill":{"duration":0.079844,"end_time":"2023-07-04T13:22:07.225601","exception":false,"start_time":"2023-07-04T13:22:07.145757","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:39.963047Z","iopub.execute_input":"2023-08-05T09:28:39.963682Z","iopub.status.idle":"2023-08-05T09:28:39.975063Z","shell.execute_reply.started":"2023-08-05T09:28:39.963644Z","shell.execute_reply":"2023-08-05T09:28:39.974005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace the imputed columns in the train data sets\ndf_train_2 = df_train.drop(df_train_numerical.columns, axis=1)\ndf_train_2 = pd.concat ([df_train_2, df_train_imputed], axis=1)\n\n# Replace the imputed columns in the test data sets\ndf_test_2 = df_test.drop(df_train_numerical.columns, axis=1)\ndf_test_2 = pd.concat ([df_test_2, df_test_imputed], axis=1)\n\n# Check the shape of the train and test data set \nprint('Shape of the Train data set : {}'.format(df_train_2.shape))\nprint('Shape of the Test data set : {}'.format(df_test_2.shape))\n","metadata":{"papermill":{"duration":0.039678,"end_time":"2023-07-04T13:22:07.291481","exception":false,"start_time":"2023-07-04T13:22:07.251803","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:39.976790Z","iopub.execute_input":"2023-08-05T09:28:39.977413Z","iopub.status.idle":"2023-08-05T09:28:39.991295Z","shell.execute_reply.started":"2023-08-05T09:28:39.977373Z","shell.execute_reply":"2023-08-05T09:28:39.990228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.2. Data Standarization for Numercial Features\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nThe RobustScaler is a data preprocessing technique available in the scikit-learn library in Python. It is used to scale numerical data in a robust manner, meaning it is less sensitive to the presence of outliers compared to other scaling methods like standardization or min-max scaling.\n</div>","metadata":{"papermill":{"duration":0.026172,"end_time":"2023-07-04T13:22:07.343477","exception":false,"start_time":"2023-07-04T13:22:07.317305","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Create a RobustScaler object\nscaler = MinMaxScaler() #RobustScaler() #StandardScaler()\n\n# Extract the index\nindex = df_train_2.index\n\n# Fit the scaler to the data and transform it\nscaler_train = scaler.fit_transform(df_train_2[df_train_numerical.columns])\nscaler_df_train = pd.DataFrame(scaler_train, columns=df_train_numerical.columns)\n\n# Reassign the index to the scaled DataFrame\nscaler_df_train.index = index\nprint('Shape of Scaled Train Data Set: {}'.format(scaler_df_train.shape))\n\n\n# Extract the index\nindex = df_test_2.index\n\nscaler_test = scaler.transform(df_test_2[df_train_numerical.columns])\nscaler_df_test = pd.DataFrame(scaler_test, columns=df_train_numerical.columns)\n\n# Reassign the index to the scaled DataFrame\nscaler_df_test.index = index\nprint('Shape of Scaled Test Data Set: {}'.format(scaler_df_test.shape))\n","metadata":{"papermill":{"duration":0.05736,"end_time":"2023-07-04T13:22:07.426898","exception":false,"start_time":"2023-07-04T13:22:07.369538","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:39.992845Z","iopub.execute_input":"2023-08-05T09:28:39.993513Z","iopub.status.idle":"2023-08-05T09:28:40.018513Z","shell.execute_reply.started":"2023-08-05T09:28:39.993470Z","shell.execute_reply":"2023-08-05T09:28:40.017407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace the scaled columns in the train data sets\ndf_train_2 = df_train_2.drop(df_train_numerical.columns, axis=1)\ndf_train_2 = pd.concat ([df_train_2, scaler_df_train], axis=1)\n\n# Replace the imputed columns in the test data sets\ndf_test_2 = df_test_2.drop(df_train_numerical.columns, axis=1)\ndf_test_2 = pd.concat ([df_test_2, scaler_df_test], axis=1)\n\n# Check the shape of the train and test data set \nprint('Shape of the Train data set : {}'.format(df_train_2.shape))\nprint('Shape of the Test data set : {}'.format(df_test_2.shape))\n","metadata":{"papermill":{"duration":0.04005,"end_time":"2023-07-04T13:22:07.493698","exception":false,"start_time":"2023-07-04T13:22:07.453648","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.020541Z","iopub.execute_input":"2023-08-05T09:28:40.021379Z","iopub.status.idle":"2023-08-05T09:28:40.041610Z","shell.execute_reply.started":"2023-08-05T09:28:40.021331Z","shell.execute_reply":"2023-08-05T09:28:40.040333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.3. Data Encoding for Categorical Features\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nCATBoostEncode, or CatBoostEncoder, is a categorical encoding technique specifically designed for the CatBoost algorithm. CatBoost is a gradient boosting algorithm that is known for its strong performance in handling categorical features. The CatBoostEncoder is a specialized encoding method that is compatible with the CatBoost algorithm and aims to effectively encode categorical variables for improved model performance.\n</div>","metadata":{"papermill":{"duration":0.026672,"end_time":"2023-07-04T13:22:07.547120","exception":false,"start_time":"2023-07-04T13:22:07.520448","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Load the CatBoost Encoder \nCATBoostENCODE = encoders.CatBoostEncoder()\n\ncategorical_cols = ['EJ']\n\n# Use CatBoost to encode the categorical values\nencoder_train = CATBoostENCODE.fit_transform(df_train[categorical_cols], df_train['Class'])\nencoded_df_train = pd.DataFrame(encoder_train)\nprint('Shape of the Encoded Train Data Set: {}'.format(encoded_df_train.shape))\n\nencoder_test = CATBoostENCODE.transform(df_test[categorical_cols])\nencoded_df_test = pd.DataFrame(encoder_test)\nprint('Shape of the Encoded Test Data Set: {}'.format(encoded_df_test.shape))","metadata":{"papermill":{"duration":0.056471,"end_time":"2023-07-04T13:22:07.630448","exception":false,"start_time":"2023-07-04T13:22:07.573977","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.043497Z","iopub.execute_input":"2023-08-05T09:28:40.044259Z","iopub.status.idle":"2023-08-05T09:28:40.077843Z","shell.execute_reply.started":"2023-08-05T09:28:40.044210Z","shell.execute_reply":"2023-08-05T09:28:40.077095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace the encoded columns in the train data sets\ndf_train_2 = df_train_2.drop(categorical_cols, axis=1)\ndf_train_2 = pd.concat ([df_train_2, encoded_df_train], axis=1)\n\n# Replace the imputed columns in the test data sets\ndf_test_2 = df_test_2.drop(categorical_cols, axis=1)\ndf_test_2 = pd.concat ([df_test_2, encoded_df_test], axis=1)\n\n# Check the shape of the train and test data set \nprint('Shape of the Train data set : {}'.format(df_train_2.shape))\nprint('Shape of the Test data set : {}'.format(df_test_2.shape))","metadata":{"papermill":{"duration":0.040791,"end_time":"2023-07-04T13:22:07.698296","exception":false,"start_time":"2023-07-04T13:22:07.657505","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.079507Z","iopub.execute_input":"2023-08-05T09:28:40.080182Z","iopub.status.idle":"2023-08-05T09:28:40.091501Z","shell.execute_reply.started":"2023-08-05T09:28:40.080142Z","shell.execute_reply":"2023-08-05T09:28:40.090465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.4. SelectKBest Method from SKLearn for Feature Selection\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nSelectKBest is a feature selection method in Scikit-learn (sklearn) library, which selects the top k features (columns) from a dataset based on some statistical test score.The basic idea behind SelectKBest is to evaluate the statistical significance of each feature using a scoring function and select the top k features with the highest scores.\n</div>","metadata":{"papermill":{"duration":0.026603,"end_time":"2023-07-04T13:22:07.751187","exception":false,"start_time":"2023-07-04T13:22:07.724584","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Before we do the oversampling, we will split the data into training and testing data for model training\ntrain = df_train_2.drop(['Id', 'Class'], axis=1)\ntest = df_train_2['Class']\n\n# Renaming the columns\ntest.columns = ['Class']\n","metadata":{"papermill":{"duration":0.037288,"end_time":"2023-07-04T13:22:07.815107","exception":false,"start_time":"2023-07-04T13:22:07.777819","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.092901Z","iopub.execute_input":"2023-08-05T09:28:40.093308Z","iopub.status.idle":"2023-08-05T09:28:40.104635Z","shell.execute_reply.started":"2023-08-05T09:28:40.093276Z","shell.execute_reply":"2023-08-05T09:28:40.103625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 0.08\nt_score = 5\n\n# Initiate the SelectKBest function\n# For regression tasks: f_regression, mutual_info_regression\n# For classification tasks: chi2, f_classif, mutual_info_classif\nfs = SelectKBest(score_func=f_classif, k=len(train.columns))\n\n# apply feature selection\nX_selected = fs.fit_transform(train, test.values)\nprint('Before the SelectKBest = {}'.format(train.shape))\n\nnew_features = [] # The list of features less than the p-values\ndrop_features = [] # The list of features higher than the p-values\n\nfor i in range(len(train.columns)):\n    print('Feature {}: {:.3f} with p-value {:.3f}'.format(train.columns[i], fs.scores_[i], fs.pvalues_[i]))\n    if fs.pvalues_[i] <= threshold and fs.scores_[i] >= t_score:\n        new_features.append(train.columns[i])\n    else:\n        drop_features.append(train.columns[i])\n\nX_selected_final =  pd.DataFrame(X_selected)\nX_selected_final.columns = train.columns\n#    print(X_selected_final.shape)\nX_selected_final = X_selected_final[new_features]\n#    print(X_selected_final.shape)\n\nprint('=' * 30)\nprint('After the SelectKBest = {}'.format(X_selected_final.shape))\nprint('Drop-out Features = {}'.format(len(drop_features)))\n","metadata":{"papermill":{"duration":0.05118,"end_time":"2023-07-04T13:22:07.893022","exception":false,"start_time":"2023-07-04T13:22:07.841842","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.106176Z","iopub.execute_input":"2023-08-05T09:28:40.106771Z","iopub.status.idle":"2023-08-05T09:28:40.125574Z","shell.execute_reply.started":"2023-08-05T09:28:40.106730Z","shell.execute_reply":"2023-08-05T09:28:40.124530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop out low informative features for model training \ntrain = train.drop(drop_features, axis=1)\ndf_train_2  = df_train_2.drop(drop_features, axis=1)\ndf_test_2  = df_test_2.drop(drop_features, axis=1)\n","metadata":{"papermill":{"duration":0.037545,"end_time":"2023-07-04T13:22:07.957572","exception":false,"start_time":"2023-07-04T13:22:07.920027","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.127229Z","iopub.execute_input":"2023-08-05T09:28:40.127789Z","iopub.status.idle":"2023-08-05T09:28:40.136034Z","shell.execute_reply.started":"2023-08-05T09:28:40.127755Z","shell.execute_reply":"2023-08-05T09:28:40.134773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.5. Oversampling with SMOTE (Synthetic Minority Over-sampling Technique)\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nSMOTE (Synthetic Minority Over-sampling Technique) is a technique  to address the problem of imbalanced datasets. Imbalanced datasets occur when the classes in the target variable are not represented equally, resulting in a skewed distribution. This is a common issue in many real-world classification problems, such as fraud detection, rare disease prediction, or anomaly detection.\n</div>","metadata":{"papermill":{"duration":0.026232,"end_time":"2023-07-04T13:22:08.011154","exception":false,"start_time":"2023-07-04T13:22:07.984922","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train, test, test_size=0.3)\n\nprint('Shape of train : {}'.format(X_train.shape))\nprint('Shape of test : {}'.format(X_test.shape))\nprint('='*50)\nprint('Shape of df_train (incl. ID and Class): {}'.format(df_train_2.shape))\nprint('Shape of df_test (incl. ID): {}'.format(df_test_2.shape))","metadata":{"papermill":{"duration":0.039497,"end_time":"2023-07-04T13:22:08.076861","exception":false,"start_time":"2023-07-04T13:22:08.037364","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.137761Z","iopub.execute_input":"2023-08-05T09:28:40.138694Z","iopub.status.idle":"2023-08-05T09:28:40.154339Z","shell.execute_reply.started":"2023-08-05T09:28:40.138653Z","shell.execute_reply":"2023-08-05T09:28:40.153415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the SMOTE library \nsmote = SMOTE(sampling_strategy={0: 360, 1: 360})\n# df_train_numerical = df_train.drop(['Id', 'EJ', 'Class'], axis=1)\n\nX_smote, y_smote = smote.fit_resample(X_train, y_train)\nprint(\"length of original data is \",len(df_train_2))\nprint(\"Proportion of True data in original data is {:.2%}\".format(len(y_train[y_train==1])/len(y_train)))\nprint(\"Proportion of False data in original data is {:.2%}\".format(len(y_train[y_train==0])/len(y_train)))\nprint(\"length of oversampled data is \",len(X_smote))\nprint(\"Proportion of True data in oversampled data is {:.2%}\".format(len(y_smote[y_smote ==1])/len(y_smote)))\nprint(\"Proportion of False data in oversampled data is {:.2%}\".format(len(y_smote[y_smote ==0])/len(y_smote)))\n   \n","metadata":{"papermill":{"duration":0.123579,"end_time":"2023-07-04T13:22:08.227174","exception":false,"start_time":"2023-07-04T13:22:08.103595","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.155667Z","iopub.execute_input":"2023-08-05T09:28:40.156288Z","iopub.status.idle":"2023-08-05T09:28:40.329100Z","shell.execute_reply.started":"2023-08-05T09:28:40.156244Z","shell.execute_reply":"2023-08-05T09:28:40.327439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Modelling","metadata":{"papermill":{"duration":0.026623,"end_time":"2023-07-04T13:22:08.281597","exception":false,"start_time":"2023-07-04T13:22:08.254974","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Parameter Setup\np_folds = 10\np_iter = 900\np_estimators = 900 #800\np_learning_rate = 0.07 #학습률 높일수록 정확도 상승(과적합 우려)","metadata":{"papermill":{"duration":0.03485,"end_time":"2023-07-04T13:22:08.343066","exception":false,"start_time":"2023-07-04T13:22:08.308216","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.330668Z","iopub.execute_input":"2023-08-05T09:28:40.331123Z","iopub.status.idle":"2023-08-05T09:28:40.339542Z","shell.execute_reply.started":"2023-08-05T09:28:40.331076Z","shell.execute_reply":"2023-08-05T09:28:40.338289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.1. XGBoost","metadata":{"papermill":{"duration":0.026763,"end_time":"2023-07-04T13:22:08.396198","exception":false,"start_time":"2023-07-04T13:22:08.369435","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# A parameter grid for XGBoost\nparams = {\n        'max_depth': randint(5, 25),\n        'gamma': uniform(0.0, 0.5),\n        'subsample': uniform(0.6, 1.0),\n        'colsample_bytree': uniform(0.5, 0.9),\n        'reg_alpha': uniform(0.0, 0.5),\n        'reg_lambda': uniform(0.0, 0.5),\n        'min_child_weight': randint(2, 6),\n        'scale_pos_weight': randint(2, 6)     \n        }","metadata":{"papermill":{"duration":0.042042,"end_time":"2023-07-04T13:22:08.464712","exception":false,"start_time":"2023-07-04T13:22:08.422670","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.340839Z","iopub.execute_input":"2023-08-05T09:28:40.341181Z","iopub.status.idle":"2023-08-05T09:28:40.356724Z","shell.execute_reply.started":"2023-08-05T09:28:40.341154Z","shell.execute_reply":"2023-08-05T09:28:40.355708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier(learning_rate=p_learning_rate, n_estimators = p_estimators) # objective='binary:logistic'","metadata":{"papermill":{"duration":0.035059,"end_time":"2023-07-04T13:22:08.526215","exception":false,"start_time":"2023-07-04T13:22:08.491156","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.357816Z","iopub.execute_input":"2023-08-05T09:28:40.358548Z","iopub.status.idle":"2023-08-05T09:28:40.368892Z","shell.execute_reply.started":"2023-08-05T09:28:40.358512Z","shell.execute_reply":"2023-08-05T09:28:40.367862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = p_folds\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 0)\n\nxg_model = RandomizedSearchCV(xgb, param_distributions=params, n_iter=p_iter, scoring='roc_auc', n_jobs=-1, cv=skf.split(X_smote,y_smote), verbose=-1, random_state=0 )\n\nxg_model.fit(X_smote, y_smote)","metadata":{"papermill":{"duration":19.136292,"end_time":"2023-07-04T13:22:27.689869","exception":false,"start_time":"2023-07-04T13:22:08.553577","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T09:28:40.370314Z","iopub.execute_input":"2023-08-05T09:28:40.370618Z","iopub.status.idle":"2023-08-05T10:03:59.627966Z","shell.execute_reply.started":"2023-08-05T09:28:40.370594Z","shell.execute_reply":"2023-08-05T10:03:59.626914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(xg_model.best_estimator_)\nprint(xg_model.best_params_)","metadata":{"papermill":{"duration":0.040826,"end_time":"2023-07-04T13:22:27.760387","exception":false,"start_time":"2023-07-04T13:22:27.719561","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:03:59.629370Z","iopub.execute_input":"2023-08-05T10:03:59.629766Z","iopub.status.idle":"2023-08-05T10:03:59.636577Z","shell.execute_reply.started":"2023-08-05T10:03:59.629738Z","shell.execute_reply":"2023-08-05T10:03:59.635573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve the best estimator and build the optimal model for analysis of Global Importance\nbest_xgb =XGBClassifier(**xg_model.best_estimator_.get_params())\nbest_xgb.fit(X_smote,y_smote)\naccuracy = best_xgb.score(X_test, y_test)\nprint('Accuracy of XGBoost : {}'.format(accuracy))","metadata":{"papermill":{"duration":0.298067,"end_time":"2023-07-04T13:22:28.087170","exception":false,"start_time":"2023-07-04T13:22:27.789103","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:03:59.637732Z","iopub.execute_input":"2023-08-05T10:03:59.638431Z","iopub.status.idle":"2023-08-05T10:04:00.854350Z","shell.execute_reply.started":"2023-08-05T10:03:59.638401Z","shell.execute_reply":"2023-08-05T10:04:00.853427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.2. LGBM","metadata":{"papermill":{"duration":0.028125,"end_time":"2023-07-04T13:22:28.144756","exception":false,"start_time":"2023-07-04T13:22:28.116631","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# params = {\n# #     'learning_rate': [0.01, 0.05, 0.1],\n# #     'n_estimators': [50, 100, 500, 1000],\n#     'num_leaves': randint(10, 30),\n#     'max_depth': randint(8, 15),\n# }\n\n# lgbm = LGBMClassifier(random_state=0, n_estimators=100, learning_rate = p_learning_rate)","metadata":{"papermill":{"duration":0.037347,"end_time":"2023-07-04T13:22:28.210550","exception":false,"start_time":"2023-07-04T13:22:28.173203","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:04:00.855803Z","iopub.execute_input":"2023-08-05T10:04:00.856139Z","iopub.status.idle":"2023-08-05T10:04:00.860326Z","shell.execute_reply.started":"2023-08-05T10:04:00.856112Z","shell.execute_reply":"2023-08-05T10:04:00.859171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# folds = p_folds\n\n# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 0)\n\n# lgbm_model = RandomizedSearchCV(lgbm, param_distributions=params, n_iter=p_iter, scoring='roc_auc', n_jobs=-1, cv=skf.split(X_smote,y_smote), verbose=-1, random_state=0 )\n\n# lgbm_model.fit(X_smote, y_smote)","metadata":{"papermill":{"duration":0.039395,"end_time":"2023-07-04T13:22:28.278398","exception":false,"start_time":"2023-07-04T13:22:28.239003","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:04:00.861807Z","iopub.execute_input":"2023-08-05T10:04:00.862134Z","iopub.status.idle":"2023-08-05T10:04:00.876998Z","shell.execute_reply.started":"2023-08-05T10:04:00.862106Z","shell.execute_reply":"2023-08-05T10:04:00.876076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(lgbm_model.best_estimator_)\n# print(lgbm_model.best_params_)","metadata":{"papermill":{"duration":0.036296,"end_time":"2023-07-04T13:22:28.343484","exception":false,"start_time":"2023-07-04T13:22:28.307188","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:04:00.878452Z","iopub.execute_input":"2023-08-05T10:04:00.879014Z","iopub.status.idle":"2023-08-05T10:04:00.890047Z","shell.execute_reply.started":"2023-08-05T10:04:00.878980Z","shell.execute_reply":"2023-08-05T10:04:00.889084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Retrieve the best estimator and build the optimal model for analysis of Global Importance\n\n# best_lgbm =LGBMClassifier(**lgbm_model.best_estimator_.get_params())\n# best_lgbm.fit(X_smote,y_smote)\n# accuracy = best_lgbm.score(X_test, y_test)\n# print('Accuracy of LGBM : {}'.format(accuracy))\n","metadata":{"papermill":{"duration":0.035828,"end_time":"2023-07-04T13:22:28.408175","exception":false,"start_time":"2023-07-04T13:22:28.372347","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:04:00.891303Z","iopub.execute_input":"2023-08-05T10:04:00.892448Z","iopub.status.idle":"2023-08-05T10:04:00.902055Z","shell.execute_reply.started":"2023-08-05T10:04:00.892413Z","shell.execute_reply":"2023-08-05T10:04:00.901033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.3. Logistic Regression","metadata":{"papermill":{"duration":0.027782,"end_time":"2023-07-04T13:22:28.464100","exception":false,"start_time":"2023-07-04T13:22:28.436318","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Specify the hyperparameter grid\n\nparams = {\n    'C': [0.1, 1, 2, 3, 5, 10,15,20],\n    'penalty': ['l1', 'l2','elasticnet'],\n    'solver': ['liblinear', 'saga'],   \n    'max_iter': [90,100, 150, 200],\n    'tol': [0.001, 0.005,0.008, 0.01,0.05,0.1]\n}\n\n# Define the logistic regression model\nlogreg = LogisticRegression()","metadata":{"papermill":{"duration":0.037539,"end_time":"2023-07-04T13:22:28.529900","exception":false,"start_time":"2023-07-04T13:22:28.492361","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:04:00.910316Z","iopub.execute_input":"2023-08-05T10:04:00.911453Z","iopub.status.idle":"2023-08-05T10:04:00.917654Z","shell.execute_reply.started":"2023-08-05T10:04:00.911411Z","shell.execute_reply":"2023-08-05T10:04:00.916620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = p_folds\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 0)\n\nlogreg_model = RandomizedSearchCV(logreg, param_distributions=params, n_iter=p_iter, scoring='roc_auc', n_jobs=-1, cv=skf.split(X_smote,y_smote), verbose=-1, random_state=0 )\n\nlogreg_model.fit(X_smote, y_smote)","metadata":{"papermill":{"duration":66.485383,"end_time":"2023-07-04T13:23:35.043305","exception":false,"start_time":"2023-07-04T13:22:28.557922","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:04:00.918767Z","iopub.execute_input":"2023-08-05T10:04:00.919588Z","iopub.status.idle":"2023-08-05T10:05:54.290094Z","shell.execute_reply.started":"2023-08-05T10:04:00.919555Z","shell.execute_reply":"2023-08-05T10:05:54.289266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(logreg_model.best_estimator_)\nprint(logreg_model.best_params_)","metadata":{"papermill":{"duration":0.042436,"end_time":"2023-07-04T13:23:35.119550","exception":false,"start_time":"2023-07-04T13:23:35.077114","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.291269Z","iopub.execute_input":"2023-08-05T10:05:54.292246Z","iopub.status.idle":"2023-08-05T10:05:54.299445Z","shell.execute_reply.started":"2023-08-05T10:05:54.292214Z","shell.execute_reply":"2023-08-05T10:05:54.298237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve the best estimator and build the optimal model for analysis of Global Importance\n\nbest_logreg =LogisticRegression(**logreg_model.best_estimator_.get_params())\nbest_logreg.fit(X_smote,y_smote)\naccuracy = best_logreg.score(X_test, y_test)\n\nprint('Accuracy of Logistic Regression : {}'.format(accuracy))","metadata":{"papermill":{"duration":0.053577,"end_time":"2023-07-04T13:23:35.205432","exception":false,"start_time":"2023-07-04T13:23:35.151855","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.302778Z","iopub.execute_input":"2023-08-05T10:05:54.304383Z","iopub.status.idle":"2023-08-05T10:05:54.323041Z","shell.execute_reply.started":"2023-08-05T10:05:54.304334Z","shell.execute_reply":"2023-08-05T10:05:54.321950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.4 CatBoost","metadata":{"papermill":{"duration":0.035611,"end_time":"2023-07-04T13:23:35.274329","exception":false,"start_time":"2023-07-04T13:23:35.238718","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# from scipy.stats import randint, uniform\n\n# params = {\n#     'max_depth': randint(5, 10),\n#     #'learning_rate': uniform(0.01, 0.2),\n#     #'l2_leaf_reg': uniform(0.0, 1.0),\n#     'subsample': uniform(0.6, 1.0),\n#     'colsample_bylevel': uniform(0.6, 1.0),\n#     'reg_lambda': uniform(0.0, 0.5),\n#     'min_child_samples': randint(3, 7),\n#     #'scale_pos_weight': randint(1, 10)\n# }","metadata":{"papermill":{"duration":0.047311,"end_time":"2023-07-04T13:23:35.354200","exception":false,"start_time":"2023-07-04T13:23:35.306889","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.326566Z","iopub.execute_input":"2023-08-05T10:05:54.326890Z","iopub.status.idle":"2023-08-05T10:05:54.334069Z","shell.execute_reply.started":"2023-08-05T10:05:54.326864Z","shell.execute_reply":"2023-08-05T10:05:54.333010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cat = CatBoostClassifier(learning_rate=p_learning_rate, n_estimators = 500)","metadata":{"papermill":{"duration":0.043577,"end_time":"2023-07-04T13:23:35.430216","exception":false,"start_time":"2023-07-04T13:23:35.386639","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.335727Z","iopub.execute_input":"2023-08-05T10:05:54.336180Z","iopub.status.idle":"2023-08-05T10:05:54.344696Z","shell.execute_reply.started":"2023-08-05T10:05:54.336142Z","shell.execute_reply":"2023-08-05T10:05:54.343917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# folds = p_folds\n\n# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 0)\n\n# cat_model = RandomizedSearchCV(cat, param_distributions=params, n_iter=500, scoring='roc_auc', n_jobs=-1, cv=skf.split(X_smote,y_smote), verbose=-1, random_state=0 )\n\n# cat_model.fit(X_smote, y_smote)","metadata":{"papermill":{"duration":138.519234,"end_time":"2023-07-04T13:25:53.982352","exception":false,"start_time":"2023-07-04T13:23:35.463118","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.345980Z","iopub.execute_input":"2023-08-05T10:05:54.346509Z","iopub.status.idle":"2023-08-05T10:05:54.359674Z","shell.execute_reply.started":"2023-08-05T10:05:54.346479Z","shell.execute_reply":"2023-08-05T10:05:54.358542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(cat_model.best_estimator_)\n# print(cat_model.best_params_)","metadata":{"papermill":{"duration":0.056747,"end_time":"2023-07-04T13:25:54.085580","exception":false,"start_time":"2023-07-04T13:25:54.028833","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.361220Z","iopub.execute_input":"2023-08-05T10:05:54.361892Z","iopub.status.idle":"2023-08-05T10:05:54.373352Z","shell.execute_reply.started":"2023-08-05T10:05:54.361851Z","shell.execute_reply":"2023-08-05T10:05:54.372058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Retrieve the best estimator and build the optimal model for analysis of Global Importance\n# best_cat =CatBoostClassifier(**cat_model.best_estimator_.get_params())\n# best_cat.fit(X_smote,y_smote)\n# accuracy = best_cat.score(X_test, y_test)\n# print('Accuracy of CatBoost : {}'.format(accuracy))","metadata":{"papermill":{"duration":1.32354,"end_time":"2023-07-04T13:25:55.455710","exception":false,"start_time":"2023-07-04T13:25:54.132170","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.375208Z","iopub.execute_input":"2023-08-05T10:05:54.375636Z","iopub.status.idle":"2023-08-05T10:05:54.384804Z","shell.execute_reply.started":"2023-08-05T10:05:54.375597Z","shell.execute_reply":"2023-08-05T10:05:54.383756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Model Performance(test set)","metadata":{"papermill":{"duration":0.046724,"end_time":"2023-07-04T13:25:55.549011","exception":false,"start_time":"2023-07-04T13:25:55.502287","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def model_performance (p_test, p_test_prob, Y_test, model_name):\n    predicted_test = pd.DataFrame(p_test)\n    print('=============================================')\n    print('Scoring Metrics for {} (Validation)'.format(model_name))\n    print('=============================================')\n    print('Balanced Accuracy Score = {:2.3f}'.format(metrics.balanced_accuracy_score(Y_test, predicted_test)))\n    print('Accuracy Score = {:2.3f}'.format(metrics.accuracy_score(Y_test, predicted_test)))\n    print('Precision Score = {:2.3f}'.format(metrics.precision_score(Y_test, predicted_test)))\n    print('F1 Score = {:2.3f}'.format(metrics.f1_score(Y_test, predicted_test, labels=['0','1'])))\n    print('Recall Score = {:2.3f}'.format(metrics.recall_score(Y_test, predicted_test, labels=['0','1'])))\n    print('ROC AUC Score = {:2.3f}'.format(metrics.roc_auc_score(Y_test, predicted_test, labels=['0','1'])))\n    print('Confusion Matrix')\n    print('==================')\n    print(metrics.confusion_matrix(Y_test, predicted_test))\n    print('==================')\n    print(metrics.classification_report(Y_test, predicted_test, target_names=['0','1']))\n    metrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_test, predicted_test)).plot()\n\n    # ROC Curve\n    fpr_test, tpr_test, _ = metrics.roc_curve(Y_test, p_test_prob)\n\n    roc_auc_test = metrics.roc_auc_score(Y_test, predicted_test, labels=['0','1'])\n\n    # Precision x Recall Curve\n    precision_test, recall_test, thresholds_test = metrics.precision_recall_curve(Y_test, p_test_prob)\n\n    print('======= ROC Curve =======')\n    fig, ax = plt.subplots(1, 1, figsize=(5, 5))    \n    plt.plot(fpr_test, tpr_test, color='darkorange', label='ROC curve - Validation (area = %0.3f)' % roc_auc_test)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    # plt.xlim([0.0, 1.0])\n    # plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc=\"lower right\")\n    \n    plt.show()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":0.064399,"end_time":"2023-07-04T13:25:55.660294","exception":false,"start_time":"2023-07-04T13:25:55.595895","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.386358Z","iopub.execute_input":"2023-08-05T10:05:54.387036Z","iopub.status.idle":"2023-08-05T10:05:54.400060Z","shell.execute_reply.started":"2023-08-05T10:05:54.386997Z","shell.execute_reply":"2023-08-05T10:05:54.399021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction for XGBoost and LGBM\n\nxg_pred_test = xg_model.predict(X_test)\nxg_proba_test = xg_model.predict_proba(X_test)[:,1]\n\n# lgbm_pred_test = lgbm_model.predict(X_test)\n# lgbm_proba_test = lgbm_model.predict_proba(X_test)[:,1]\n\nlogreg_pred_test = logreg_model.predict(X_test)\nlogreg_proba_test = logreg_model.predict_proba(X_test)[:,1]\n\n# cat_pred_test = cat_model.predict(X_test)\n# cat_proba_test = cat_model.predict_proba(X_test)[:,1]","metadata":{"_kg_hide-output":false,"papermill":{"duration":0.069661,"end_time":"2023-07-04T13:25:55.777048","exception":false,"start_time":"2023-07-04T13:25:55.707387","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.401701Z","iopub.execute_input":"2023-08-05T10:05:54.402129Z","iopub.status.idle":"2023-08-05T10:05:54.428242Z","shell.execute_reply.started":"2023-08-05T10:05:54.402090Z","shell.execute_reply":"2023-08-05T10:05:54.427144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_performance(xg_pred_test, xg_proba_test, y_test, 'XGBoost')\n\n# Use the roc_auc measure as a weighting to the meta classification decision\nxg_roc_auc = metrics.roc_auc_score(y_test, xg_pred_test, labels=['0','1'])","metadata":{"papermill":{"duration":0.626758,"end_time":"2023-07-04T13:25:56.451600","exception":false,"start_time":"2023-07-04T13:25:55.824842","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.430003Z","iopub.execute_input":"2023-08-05T10:05:54.430433Z","iopub.status.idle":"2023-08-05T10:05:54.985652Z","shell.execute_reply.started":"2023-08-05T10:05:54.430393Z","shell.execute_reply":"2023-08-05T10:05:54.984830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_performance(lgbm_pred_test, lgbm_proba_test, y_test, 'LGBM')\n\n# # Use the roc_auc measure as a weighting to the meta classification decision\n# lgbm_roc_auc = metrics.roc_auc_score(y_test, lgbm_pred_test, labels=['0','1'])","metadata":{"papermill":{"duration":0.056555,"end_time":"2023-07-04T13:25:56.557021","exception":false,"start_time":"2023-07-04T13:25:56.500466","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.986907Z","iopub.execute_input":"2023-08-05T10:05:54.987438Z","iopub.status.idle":"2023-08-05T10:05:54.991617Z","shell.execute_reply.started":"2023-08-05T10:05:54.987407Z","shell.execute_reply":"2023-08-05T10:05:54.990382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_performance(logreg_pred_test, logreg_proba_test, y_test, 'Logistic Regression')\n\n# Use the roc_auc measure as a weighting to the meta classification decision\nlogreg_roc_auc = metrics.roc_auc_score(y_test, logreg_pred_test, labels=['0','1'])","metadata":{"papermill":{"duration":0.62708,"end_time":"2023-07-04T13:25:57.231848","exception":false,"start_time":"2023-07-04T13:25:56.604768","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:54.993448Z","iopub.execute_input":"2023-08-05T10:05:54.993849Z","iopub.status.idle":"2023-08-05T10:05:55.513731Z","shell.execute_reply.started":"2023-08-05T10:05:54.993811Z","shell.execute_reply":"2023-08-05T10:05:55.512464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_performance(cat_pred_test, cat_proba_test, y_test, 'CatBoost')\n\n# # Use the roc_auc measure as a weighting to the meta classification decision\n# cat_roc_auc = metrics.roc_auc_score(y_test, cat_pred_test, labels=['0','1'])","metadata":{"papermill":{"duration":0.744485,"end_time":"2023-07-04T13:25:58.025101","exception":false,"start_time":"2023-07-04T13:25:57.280616","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:55.515400Z","iopub.execute_input":"2023-08-05T10:05:55.515828Z","iopub.status.idle":"2023-08-05T10:05:55.522749Z","shell.execute_reply.started":"2023-08-05T10:05:55.515786Z","shell.execute_reply":"2023-08-05T10:05:55.521636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.1. Model Explanation","metadata":{"papermill":{"duration":0.071032,"end_time":"2023-07-04T13:25:58.171628","exception":false,"start_time":"2023-07-04T13:25:58.100596","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def model_explanation (model_name, name):\n\n    # Explain the Global Importance\n    importances = model_name.feature_importances_\n\n    # Get the indices of the top 20 features.\n    top_indices = importances.argsort()[::-1][:20]\n\n    # Get the names of the top 20 features.\n    top_feature_names = X_smote.columns[top_indices]\n\n    # Get the importances of the top 20 features.\n    top_importances = importances[top_indices]\n\n    # Plot the feature importances for the top 20 features.\n    plt.figure(figsize = (10, 6))\n    plt.bar(range(len(top_feature_names)), top_importances)\n    plt.xticks(range(len(top_feature_names)), top_feature_names, rotation = 90)\n    plt.xlabel('Features')\n    plt.ylabel('Importance')\n    plt.title('Top 20 Feature Importance - ' + name)\n    plt.tight_layout()\n    plt.show()","metadata":{"papermill":{"duration":0.098927,"end_time":"2023-07-04T13:25:58.341636","exception":false,"start_time":"2023-07-04T13:25:58.242709","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:55.524089Z","iopub.execute_input":"2023-08-05T10:05:55.524399Z","iopub.status.idle":"2023-08-05T10:05:55.532920Z","shell.execute_reply.started":"2023-08-05T10:05:55.524372Z","shell.execute_reply":"2023-08-05T10:05:55.532147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Global Importance for XGBoost\nmodel_explanation(best_xgb, 'XGBoost')","metadata":{"papermill":{"duration":0.650231,"end_time":"2023-07-04T13:25:59.067013","exception":false,"start_time":"2023-07-04T13:25:58.416782","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:55.534243Z","iopub.execute_input":"2023-08-05T10:05:55.534968Z","iopub.status.idle":"2023-08-05T10:05:55.883073Z","shell.execute_reply.started":"2023-08-05T10:05:55.534911Z","shell.execute_reply":"2023-08-05T10:05:55.881988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Global Importance for LGBM\n# model_explanation(best_lgbm, 'LGBM')","metadata":{"papermill":{"duration":0.059043,"end_time":"2023-07-04T13:25:59.191617","exception":false,"start_time":"2023-07-04T13:25:59.132574","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:55.884505Z","iopub.execute_input":"2023-08-05T10:05:55.885466Z","iopub.status.idle":"2023-08-05T10:05:55.892581Z","shell.execute_reply.started":"2023-08-05T10:05:55.885425Z","shell.execute_reply":"2023-08-05T10:05:55.891642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Global Importance for Logistic Regression\n# model_explanation(best_logreg, 'Logistic Regression')","metadata":{"papermill":{"duration":0.969671,"end_time":"2023-07-04T13:26:00.211561","exception":false,"start_time":"2023-07-04T13:25:59.241890","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:55.893975Z","iopub.execute_input":"2023-08-05T10:05:55.894519Z","iopub.status.idle":"2023-08-05T10:05:55.901816Z","shell.execute_reply.started":"2023-08-05T10:05:55.894483Z","shell.execute_reply":"2023-08-05T10:05:55.900910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Global Importance for CatBoost\n# model_explanation(best_cat, 'CatBoost')","metadata":{"papermill":{"duration":0.492622,"end_time":"2023-07-04T13:26:00.756071","exception":false,"start_time":"2023-07-04T13:26:00.263449","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:55.903351Z","iopub.execute_input":"2023-08-05T10:05:55.903777Z","iopub.status.idle":"2023-08-05T10:05:55.915913Z","shell.execute_reply.started":"2023-08-05T10:05:55.903736Z","shell.execute_reply":"2023-08-05T10:05:55.914661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Prediction and Submission","metadata":{"papermill":{"duration":0.055786,"end_time":"2023-07-04T13:26:00.864398","exception":false,"start_time":"2023-07-04T13:26:00.808612","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Use the roc_auc as weighting in the meta classification\n\n# prediction probability of XGBoost\nxg_pred = xg_model.predict_proba(df_test_2.drop(['Id'], axis=1))\nprint('========== XGBoost ==========')\nprint(xg_pred)\n\n# # prediction probability of LGBM\n# lgbm_pred = lgbm_model.predict_proba(df_test_2.drop(['Id'], axis=1))\n# print('========== LGBM ==========')\n# print(lgbm_pred)\n\n# prediction probability of Logistic Regression\nlogreg_pred = logreg_model.predict_proba(df_test_2.drop(['Id'], axis=1))\nprint('========== Logistic Regression ==========')\nprint(logreg_pred)\n\n# # prediction probability of CatBoost \n# cat_pred = cat_model.predict_proba(df_test_2.drop(['Id'], axis=1))\n# print('========== CatBoost ==========')\n# print(cat_pred)\n","metadata":{"papermill":{"duration":0.08797,"end_time":"2023-07-04T13:26:01.004565","exception":false,"start_time":"2023-07-04T13:26:00.916595","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:55.917515Z","iopub.execute_input":"2023-08-05T10:05:55.918420Z","iopub.status.idle":"2023-08-05T10:05:55.938618Z","shell.execute_reply.started":"2023-08-05T10:05:55.918372Z","shell.execute_reply":"2023-08-05T10:05:55.937173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # weight of XGBoost\n# xg_weight = xg_roc_auc/(xg_roc_auc + lgbm_roc_auc+ logreg_roc_auc + cat_roc_auc)\n# lgbm_weight = lgbm_roc_auc/(xg_roc_auc + lgbm_roc_auc+ logreg_roc_auc + cat_roc_auc)\n# logreg_weight = logreg_roc_auc/(xg_roc_auc + lgbm_roc_auc+ logreg_roc_auc + cat_roc_auc)\n# cat_weight = cat_roc_auc/(xg_roc_auc + lgbm_roc_auc+ logreg_roc_auc + cat_roc_auc)\n\n# print('Weight of XGBoost : {}, Weight of LGBM : {}, Weight of Reg : {}, Weight of Cat : {}'.format(xg_weight, lgbm_weight, logreg_weight, cat_weight))\n","metadata":{"papermill":{"duration":0.111656,"end_time":"2023-07-04T13:26:01.281244","exception":false,"start_time":"2023-07-04T13:26:01.169588","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:55.940496Z","iopub.execute_input":"2023-08-05T10:05:55.941345Z","iopub.status.idle":"2023-08-05T10:05:55.946419Z","shell.execute_reply.started":"2023-08-05T10:05:55.941303Z","shell.execute_reply":"2023-08-05T10:05:55.945261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # weight of XGBoost\n# xg_weight = xg_roc_auc/(lgbm_roc_auc + xg_roc_auc + cat_roc_auc)\n# lgbm_weight = lgbm_roc_auc/(lgbm_roc_auc + xg_roc_auc + cat_roc_auc)\n# cat_weight = cat_roc_auc/(lgbm_roc_auc + xg_roc_auc + cat_roc_auc)\n\n# print('Weight of XGBoost : {}, Weight of LGBM : {}, Weight of Cat : {}'.format(xg_weight, lgbm_weight, cat_weight))\n","metadata":{"papermill":{"duration":0.060603,"end_time":"2023-07-04T13:26:01.118243","exception":false,"start_time":"2023-07-04T13:26:01.057640","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:55.948057Z","iopub.execute_input":"2023-08-05T10:05:55.948726Z","iopub.status.idle":"2023-08-05T10:05:55.964030Z","shell.execute_reply.started":"2023-08-05T10:05:55.948686Z","shell.execute_reply":"2023-08-05T10:05:55.963046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # weight of XGBoost\n# xg_weight = xg_roc_auc/(xg_roc_auc)\n# # lgbm_weight = lgbm_roc_auc/(xg_roc_auc + lgbm_roc_auc+ logreg_roc_auc + cat_roc_auc)\n# #logreg_weight = logreg_roc_auc/(xg_roc_auc + logreg_roc_auc)\n# #cat_weight = cat_roc_auc/(xg_roc_auc + logreg_roc_auc + cat_roc_auc)\n\n# print('Weight of XGBoost : {}'.format(xg_weight))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-05T10:05:55.965619Z","iopub.execute_input":"2023-08-05T10:05:55.966400Z","iopub.status.idle":"2023-08-05T10:05:55.977762Z","shell.execute_reply.started":"2023-08-05T10:05:55.966358Z","shell.execute_reply":"2023-08-05T10:05:55.976666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# weight of XGBoost\nxg_weight = xg_roc_auc/(xg_roc_auc + logreg_roc_auc)\n#lgbm_weight = lgbm_roc_auc/(xg_roc_auc + lgbm_roc_auc+ logreg_roc_auc)\nlogreg_weight = logreg_roc_auc/(xg_roc_auc + logreg_roc_auc)\n#cat_weight = cat_roc_auc/(xg_roc_auc + lgbm_roc_auc+ logreg_roc_auc + cat_roc_auc)\n\nprint('Weight of XGBoost : {}, Weight of Reg : {} '.format(xg_weight, logreg_weight))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-05T10:05:55.979534Z","iopub.execute_input":"2023-08-05T10:05:55.979985Z","iopub.status.idle":"2023-08-05T10:05:55.992641Z","shell.execute_reply.started":"2023-08-05T10:05:55.979926Z","shell.execute_reply":"2023-08-05T10:05:55.991476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = df_test_2[['Id']].copy()\n# submission['Class_0'] = (xg_pred[:,0] * xg_weight) + (logreg_pred[:,0] * logreg_weight) + (cat_pred[:,0] * cat_weight)\n# submission['Class_1'] = (xg_pred[:,1] * xg_weight) + (logreg_pred[:,1] * logreg_weight) + (cat_pred[:,1] * cat_weight)\n# submission.to_csv('submission.csv',index=False)\n# submission.head()","metadata":{"papermill":{"duration":0.076017,"end_time":"2023-07-04T13:26:01.524035","exception":false,"start_time":"2023-07-04T13:26:01.448018","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:55.994151Z","iopub.execute_input":"2023-08-05T10:05:55.994841Z","iopub.status.idle":"2023-08-05T10:05:56.004611Z","shell.execute_reply.started":"2023-08-05T10:05:55.994799Z","shell.execute_reply":"2023-08-05T10:05:56.003479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = df_test_2[['Id']].copy()\n# submission['Class_0'] = (xg_pred[:,0] * xg_weight) + (lgbm_pred[:,0] * lgbm_weight) + (cat_pred[:,0] * cat_weight)\n# submission['Class_1'] = (xg_pred[:,1] * xg_weight) + (lgbm_pred[:,1] * lgbm_weight) + (cat_pred[:,1] * cat_weight)\n# submission.to_csv('submission.csv',index=False)\n# submission.head()","metadata":{"papermill":{"duration":0.062366,"end_time":"2023-07-04T13:26:01.395990","exception":false,"start_time":"2023-07-04T13:26:01.333624","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:56.006287Z","iopub.execute_input":"2023-08-05T10:05:56.006611Z","iopub.status.idle":"2023-08-05T10:05:56.017091Z","shell.execute_reply.started":"2023-08-05T10:05:56.006584Z","shell.execute_reply":"2023-08-05T10:05:56.016010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = df_test_2[['Id']].copy()\n# submission['Class_0'] = (xg_pred[:,0] * xg_weight)\n# submission['Class_1'] = (xg_pred[:,1] * xg_weight)\n# submission.to_csv('submission.csv',index=False)\n# submission.head()","metadata":{"papermill":{"duration":0.051916,"end_time":"2023-07-04T13:26:01.628869","exception":false,"start_time":"2023-07-04T13:26:01.576953","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-05T10:05:56.018342Z","iopub.execute_input":"2023-08-05T10:05:56.019283Z","iopub.status.idle":"2023-08-05T10:05:56.031879Z","shell.execute_reply.started":"2023-08-05T10:05:56.019252Z","shell.execute_reply":"2023-08-05T10:05:56.030644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = df_test_2[['Id']].copy()\nsubmission['Class_0'] = (xg_pred[:,0] * xg_weight) + (logreg_pred[:,0] * logreg_weight)\nsubmission['Class_1'] = (xg_pred[:,1] * xg_weight) + (logreg_pred[:,1] * logreg_weight)\nsubmission.to_csv('submission.csv',index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T10:05:56.033648Z","iopub.execute_input":"2023-08-05T10:05:56.034077Z","iopub.status.idle":"2023-08-05T10:05:56.059395Z","shell.execute_reply.started":"2023-08-05T10:05:56.034040Z","shell.execute_reply":"2023-08-05T10:05:56.058047Z"},"trusted":true},"execution_count":null,"outputs":[]}]}